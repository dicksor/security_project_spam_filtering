{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email spam detection using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process we will use to train a predictive model to detect if an email is ham or spam is as follows : \n",
    " * We will read the dataset that contains 5000 different spam/ham emails\n",
    " * We will transform this textual dataset into numeric vectors that our models can use\n",
    " * We will train a model to predict if an email is ham/spam\n",
    " * We will evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data processing\n",
    "We will read the file \"email.csv\" containing all our spam/ham email. The dataset contains a total of 5727 different emails, where 4361 are ham and 1369 are spam. These emails will be contained in a pandas **Dataframe**, an array-like object that allows to easely manipulate large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./emails.csv.zip\", encoding= \"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataframe is an array that contains two columns, the column **text** which contains the email itself and the column **spam** which is a binary value that classifies the email as **0** for **ham** and **1** for **spam**. This means that each row of the Dataframe represents a single email that is either a spam or ham. \n",
    "\n",
    "We can see this clearly if we show the content on the Dataframe as below : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Subject: great nnews  hello , welcome to medzo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Subject: here ' s a hot play in motion  homela...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Subject: save your money buy getting this thin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Subject: undeliverable : home based business f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Subject: save your money buy getting this thin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Subject: las vegas high rise boom  las vegas i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Subject: save your money buy getting this thin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Subject: brighten those teeth  get your  teeth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Subject: wall street phenomenon reaps rewards ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Subject: fpa notice : ebay misrepresentation o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Subject: search engine position  be the very f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Subject: only our software is guaranteed 100 %...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Subject: localized software , all languages av...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Subject: security alert - confirm your nationa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Subject: 21 st century web specialists jrgbm  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Subject: any med for your girl to be happy !  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Subject: re : wearable electronics  hi my name...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Subject: top - level logo and business identit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Subject: your trusted source for prescription ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Subject: rely on us for your online prescripti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Subject: guzzle like a fountain  spur m rocks ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Subject: are you losing ? the answer would ama...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Subject: hi  how to save o improper n your med...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Subject: 25 mg did thhe trick  ho receivable w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Subject: save your money buy getting this thin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5698</th>\n",
       "      <td>Subject: schedule and more . .  dr . kaminski ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5699</th>\n",
       "      <td>Subject: re : message from ken rice  vince :  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5700</th>\n",
       "      <td>Subject: re : exploration data as the root of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5701</th>\n",
       "      <td>Subject: rendez - vous reporter : sunday 3 rd ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>Subject: dr . michelle foss - energy institute...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>Subject: rice / enron finance seminar series  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>Subject: storage model security  stinson ,  i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>Subject: re : meeting w kevin hannon  vince an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>Subject: e - mail and voicemail retention poli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5707</th>\n",
       "      <td>Subject: approval is overdue : access request ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708</th>\n",
       "      <td>Subject: re : hi vince  hi jeff ,  no problem ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5709</th>\n",
       "      <td>Subject: agenda for larry thorne ' s presentat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5710</th>\n",
       "      <td>Subject: raptors  here is the most recent vers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5711</th>\n",
       "      <td>Subject: re : faculty lunch  alison ,  i recom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5712</th>\n",
       "      <td>Subject: 2 - survey / information email 5 - 7 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5713</th>\n",
       "      <td>Subject: promotion  vince , i want to congratu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5714</th>\n",
       "      <td>Subject: re : petronas benchmarking visit  fyi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5715</th>\n",
       "      <td>Subject: request submitted : access request fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5716</th>\n",
       "      <td>Subject: * special notification * aurora versi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5717</th>\n",
       "      <td>Subject: fwd : update  return - path :  receiv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5718</th>\n",
       "      <td>Subject: altos na gas model  kim , i know you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>Subject: power market research  i came across ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>Subject: re : visit to houston  fyi  - - - - -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>Subject: ees risk management presentations for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>Subject: re : vacation  vince :  i just found ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>Subject: re : research and development charges...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>Subject: re : receipts from visit  jim ,  than...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>Subject: re : enron case study update  wow ! a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>Subject: re : interest  david ,  please , call...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Subject: news : aurora 5 . 2 update  aurora ve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam\n",
       "0     Subject: naturally irresistible your corporate...     1\n",
       "1     Subject: the stock trading gunslinger  fanny i...     1\n",
       "2     Subject: unbelievable new homes made easy  im ...     1\n",
       "3     Subject: 4 color printing special  request add...     1\n",
       "4     Subject: do not have money , get software cds ...     1\n",
       "5     Subject: great nnews  hello , welcome to medzo...     1\n",
       "6     Subject: here ' s a hot play in motion  homela...     1\n",
       "7     Subject: save your money buy getting this thin...     1\n",
       "8     Subject: undeliverable : home based business f...     1\n",
       "9     Subject: save your money buy getting this thin...     1\n",
       "10    Subject: las vegas high rise boom  las vegas i...     1\n",
       "11    Subject: save your money buy getting this thin...     1\n",
       "12    Subject: brighten those teeth  get your  teeth...     1\n",
       "13    Subject: wall street phenomenon reaps rewards ...     1\n",
       "14    Subject: fpa notice : ebay misrepresentation o...     1\n",
       "15    Subject: search engine position  be the very f...     1\n",
       "16    Subject: only our software is guaranteed 100 %...     1\n",
       "17    Subject: localized software , all languages av...     1\n",
       "18    Subject: security alert - confirm your nationa...     1\n",
       "19    Subject: 21 st century web specialists jrgbm  ...     1\n",
       "20    Subject: any med for your girl to be happy !  ...     1\n",
       "21    Subject: re : wearable electronics  hi my name...     1\n",
       "22    Subject: top - level logo and business identit...     1\n",
       "23    Subject: your trusted source for prescription ...     1\n",
       "24    Subject: rely on us for your online prescripti...     1\n",
       "25    Subject: guzzle like a fountain  spur m rocks ...     1\n",
       "26    Subject: are you losing ? the answer would ama...     1\n",
       "27    Subject: hi  how to save o improper n your med...     1\n",
       "28    Subject: 25 mg did thhe trick  ho receivable w...     1\n",
       "29    Subject: save your money buy getting this thin...     1\n",
       "...                                                 ...   ...\n",
       "5698  Subject: schedule and more . .  dr . kaminski ...     0\n",
       "5699  Subject: re : message from ken rice  vince :  ...     0\n",
       "5700  Subject: re : exploration data as the root of ...     0\n",
       "5701  Subject: rendez - vous reporter : sunday 3 rd ...     0\n",
       "5702  Subject: dr . michelle foss - energy institute...     0\n",
       "5703  Subject: rice / enron finance seminar series  ...     0\n",
       "5704  Subject: storage model security  stinson ,  i ...     0\n",
       "5705  Subject: re : meeting w kevin hannon  vince an...     0\n",
       "5706  Subject: e - mail and voicemail retention poli...     0\n",
       "5707  Subject: approval is overdue : access request ...     0\n",
       "5708  Subject: re : hi vince  hi jeff ,  no problem ...     0\n",
       "5709  Subject: agenda for larry thorne ' s presentat...     0\n",
       "5710  Subject: raptors  here is the most recent vers...     0\n",
       "5711  Subject: re : faculty lunch  alison ,  i recom...     0\n",
       "5712  Subject: 2 - survey / information email 5 - 7 ...     0\n",
       "5713  Subject: promotion  vince , i want to congratu...     0\n",
       "5714  Subject: re : petronas benchmarking visit  fyi...     0\n",
       "5715  Subject: request submitted : access request fo...     0\n",
       "5716  Subject: * special notification * aurora versi...     0\n",
       "5717  Subject: fwd : update  return - path :  receiv...     0\n",
       "5718  Subject: altos na gas model  kim , i know you ...     0\n",
       "5719  Subject: power market research  i came across ...     0\n",
       "5720  Subject: re : visit to houston  fyi  - - - - -...     0\n",
       "5721  Subject: ees risk management presentations for...     0\n",
       "5722  Subject: re : vacation  vince :  i just found ...     0\n",
       "5723  Subject: re : research and development charges...     0\n",
       "5724  Subject: re : receipts from visit  jim ,  than...     0\n",
       "5725  Subject: re : enron case study update  wow ! a...     0\n",
       "5726  Subject: re : interest  david ,  please , call...     0\n",
       "5727  Subject: news : aurora 5 . 2 update  aurora ve...     0\n",
       "\n",
       "[5728 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also show the amount of emails (or rows) that there are for each type of email (spam/ham). In this dataset we have way more ham than spam, this is normal since it reflects what we would recieve on a daily basis in our inbox, which is more ham than spam. We will first train and test our model using this inequality, later in the notebook we will repeat the while process, but with an equal amount of spam/ham emails to see if the model is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4360\n",
       "1    1368\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.spam.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test with a dataset with equal number of spam/ham emails\n",
    "# data = pd.concat([data[:1000], data[-1000:]], axis=0)\n",
    "# data.spam.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split our dataset into two parts: \n",
    "   * training set: The dataset used to train our model\n",
    "   * test set: The dataset used to validate if the model is good\n",
    "   \n",
    "The training will contain 80% of the data while the test set will only contain 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(data[\"text\"],data[\"spam\"], test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Vectorisation of the data\n",
    "Since our models can only work with numerical vectors, we need to tranforms the textual data into such vectors. We will use a **CountVectorizer** from scikit to do such task. The idea is to first extract every unique word contained in all of our email dataset while filtering out english **stop_words**, these are common words found in the english language. We remove these common words because they don't influence the meaning of the email, they are words that we would equally find in ham and spam email. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Finding every unique word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words=\"english\")\n",
    "vect.fit(train_X) # Find some word that cause most of spam email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '000000000003619', '000000000003991', '000000000005411', '000000000007498', '000000000007876', '000000000012734', '000010220', '0000102317', '0000102374', '0000104486', '0000104631', '0000104730', '0000104776', '0000104778', '0001', '0002', '0003']\n"
     ]
    }
   ],
   "source": [
    "# show first 20 unique words used in all the emails\n",
    "print(vect.get_feature_names()[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zt', 'ztvwo', 'zucha', 'zuerich', 'zuid', 'zulie', 'zulkifli', 'zum', 'zunf', 'zungenakrobatik', 'zurich', 'zustellstatus', 'zuyw', 'zwischen', 'zwzm', 'zxghlajf', 'zyban', 'zygoma', 'zymg', 'zzzz']\n"
     ]
    }
   ],
   "source": [
    "# show last 20 unique words used in all the emails\n",
    "print(vect.get_feature_names()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20952"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Transforming the emails into vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use these unique words to create our vectors. For each email a vector will be created, the vector contains the number of occurence of every unique word in the specified email.\n",
    "\n",
    "Example:\n",
    "We have the following three sentences: \n",
    "* 'Spam emails are bad'\n",
    "* 'The red apple is juicy'\n",
    "* 'The blue sky is blue tonight'\n",
    "\n",
    "We now have these unique words ['apple', 'bad', 'blue', 'emails', 'juicy', 'red', 'sky', 'spam', 'tonight']   \n",
    "Each of these sentences will be transformed into a one dimentional vector containing the number of occurence of each unique word as such: \n",
    "\n",
    "|                              | apple | bad | blue | emails | juicy | red | sky | spam | tonight |\n",
    "|------------------------------|:-----:|:---:|:----:|:------:|:-----:|:---:|:---:|:----:|:-------:|\n",
    "| Spam emails are bad          |   0   |  1  |   0  |    1   |   0   |  0  |  0  |   1  |    0    |\n",
    "| The red apple is juicy       |   1   |  0  |   0  |    0   |   1   |  1  |  0  |   0  |    0    |\n",
    "| The blue sky is blue tonight |   0   |  0  |   2  |    0   |   0   |  0  |  1  |   0  |    1    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_occurence = vect.transform(train_X)\n",
    "X_test_occurence = vect.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now transformed both our training and test data set into a matrix. Below is the size of our matrix, we can notice that the number of rows is equal to the size of the train set and the number of columns is equal to the number of unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 20952)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_occurence.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Training our model\n",
    "Now that the data is processed, we will use it to train our model. We use Naive Bayes, a commonly machine learning algorithm for classification of textual data. After training out model we will use the test set to validate the precision of the model, meaning how many time the model had the right prediction on if the email is a spam of ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9825"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train_occurence,train_y)\n",
    "pred = model.predict(X_test_occurence)\n",
    "accuracy_score(test_y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following matrix can be read as such : \n",
    "* Top-left: number of emails rightfully classified as ham\n",
    "* Top-right: number of emails wrongfully classified as ham\n",
    "* Bottom-left: number of emails wrongfully classified as spam\n",
    "* Bottom-right: number of emails rightfully classified as spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[192,   3],\n",
       "       [  4, 201]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Trying out the model\n",
    "Now that our model is trained and validated, we will test it using \"real\" emails we have recieved in our inbox. To do this we will first have to store the content of the email in a variable and add it to the original data. We will then use our occurence transformer to convert our data into a matrix. Finally we will use the model to try to predict if the given email is spam or ham."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spam email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = 'ALWAYS THERE FOR YOU: WE DELIVER YOUR PIZZA WITHOUT CONTACT Domino\\'s Pizza attaches great importance to the health of its employees and customers. That is why Domino\\'s Pizza Switzerland strictly adheres to the recommendations and regulations of the Federal Office of Public Health regarding the coronavirus. We do everything possible to ensure that customers can continue to enjoy their pizza comfortably and above all safely at work, in the home office or in the evening using Domino\\'s Pizza\\'s delivery service! To protect its employees and customers, Domino\\'s Pizza was the first company to use contactless delivery and last week closed all take-away areas as a precautionary measure. In addition, the employees of Domino\\'s Pizza Switzerland work under strict hygiene measures and keep a minimum distance. At Domino\\'s Pizza, all ingredients are baked - in the oven at 250 degrees for 6 minutes - after which the pizza is placed directly into its box. From now on and as an extra measure, the pizza will no longer be sliced. Because Domino\\'s controls the entire chain (production and delivery), we can guarantee the best possible hygiene conditions - from production to your door! Order online and we take care of everything! Domino’s Pizza Suisse #WECAREFORYOU #STAYATHOME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ALWAYS THERE FOR YOU: WE DELIVER YOUR PIZZA WITHOUT CONTACT Domino's Pizza attaches great importance to the health of its employees and customers. That is why Domino's Pizza Switzerland strictly adheres to the recommendations and regulations of the Federal Office of Public Health regarding the coronavirus. We do everything possible to ensure that customers can continue to enjoy their pizza comfortably and above all safely at work, in the home office or in the evening using Domino's Pizza's delivery service! To protect its employees and customers, Domino's Pizza was the first company to use contactless delivery and last week closed all take-away areas as a precautionary measure. In addition, the employees of Domino's Pizza Switzerland work under strict hygiene measures and keep a minimum distance. At Domino's Pizza, all ingredients are baked - in the oven at 250 degrees for 6 minutes - after which the pizza is placed directly into its box. From now on and as an extra measure, the pizza will no longer be sliced. Because Domino's controls the entire chain (production and delivery), we can guarantee the best possible hygiene conditions - from production to your door! Order online and we take care of everything! Domino’s Pizza Suisse #WECAREFORYOU #STAYATHOME\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'text':email, 'spam':1}\n",
    "#append row to the dataframe\n",
    "data = data.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALWAYS THERE FOR YOU: WE DELIVER YOUR PIZZA WITHOUT CONTACT Domino's Pizza attaches great importance to the health of its employees and customers. That is why Domino's Pizza Switzerland strictly adheres to the recommendations and regulations of the Federal Office of Public Health regarding the coronavirus. We do everything possible to ensure that customers can continue to enjoy their pizza comfortably and above all safely at work, in the home office or in the evening using Domino's Pizza's delivery service! To protect its employees and customers, Domino's Pizza was the first company to use contactless delivery and last week closed all take-away areas as a precautionary measure. In addition, the employees of Domino's Pizza Switzerland work under strict hygiene measures and keep a minimum distance. At Domino's Pizza, all ingredients are baked - in the oven at 250 degrees for 6 minutes - after which the pizza is placed directly into its box. From now on and as an extra measure, the pizza will no longer be sliced. Because Domino's controls the entire chain (production and delivery), we can guarantee the best possible hygiene conditions - from production to your door! Order online and we take care of everything! Domino’s Pizza Suisse #WECAREFORYOU #STAYATHOME\n",
      "---------------------------------\n",
      "Prediction:  1\n",
      "Actual category:  1\n"
     ]
    }
   ],
   "source": [
    "print(data[\"text\"].iloc[-1])\n",
    "pred = model.predict(vect.transform(data[\"text\"]))\n",
    "print(\"---------------------------------\")\n",
    "print(\"Prediction: \",pred[-1])\n",
    "print(\"Actual category: \",data[\"spam\"].iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ham email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = \"Hello Mr. Marina, .Here is what we have done for the lesson of the day :. We discussed about training a machine learning model using the library Scikit-Learn for filtering out spam. We found an existing dataset of ham/spam emails containing 5'000 entities . We are going to write our own ham/spam email to test our training model. We discussed about the structure of the presentation (Power Point, Jupyter Notebook, ...). We finished reading the PDF course about spam filtering. We wish you a good afternoon. Kind Regards, Vincent Moulin and Nicolas Praz Group 7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Mr. Marina, .Here is what we have done for the lesson of the day :. We discussed about training a machine learning model using the library Scikit-Learn for filtering out spam. We found an existing dataset of ham/spam emails containing 5'000 entities . We are going to write our own ham/spam email to test our training model. We discussed about the structure of the presentation (Power Point, Jupyter Notebook, ...). We finished reading the PDF course about spam filtering. We wish you a good afternoon. Kind Regards, Vincent Moulin and Nicolas Praz Group 7\n",
      "---------------------------------\n",
      "Prediction:  0\n",
      "Actual category:  0\n"
     ]
    }
   ],
   "source": [
    "new_row = {'text':ham, 'spam':0}\n",
    "#append row to the dataframe\n",
    "data = data.append(new_row, ignore_index=True)\n",
    "print(data[\"text\"].iloc[-1])\n",
    "pred = model.predict(vect.transform(data[\"text\"]))\n",
    "print(\"---------------------------------\")\n",
    "print(\"Prediction: \",pred[-1])\n",
    "print(\"Actual category: \",data[\"spam\"].iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = 'Hello everyone, We are the team behind usepanda.com, flatuicolors.com, collectui.com and thestocks.im. You can see all the tools we are building on Asteya Network website. Your email has been registered in one of the websites above (maybe years ago) and this is the first time that we are sending you an update of a new product that we have built Launching Today Introducing Corona Panel v2, which we built by gathering all the useful resources related to the Covid-19 Pandemic in one place. Words cannot explain well enough, please go ahead and check it yourself: https://coronapanel.com What\\’s Next? We are building a news reader app for iOS and Android. You can read Hacker News, Dribbble, Designers News, Product Hunt and many more on the go. We\\’ll send you another email as we launch Stay Strong and Safe Asteya Network Team https://asteya.network'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello everyone, We are the team behind usepanda.com, flatuicolors.com, collectui.com and thestocks.im. You can see all the tools we are building on Asteya Network website. Your email has been registered in one of the websites above (maybe years ago) and this is the first time that we are sending you an update of a new product that we have built Launching Today Introducing Corona Panel v2, which we built by gathering all the useful resources related to the Covid-19 Pandemic in one place. Words cannot explain well enough, please go ahead and check it yourself: https://coronapanel.com What\\’s Next? We are building a news reader app for iOS and Android. You can read Hacker News, Dribbble, Designers News, Product Hunt and many more on the go. We\\’ll send you another email as we launch Stay Strong and Safe Asteya Network Team https://asteya.network\n",
      "---------------------------------\n",
      "Prediction:  1\n",
      "Actual category:  1\n"
     ]
    }
   ],
   "source": [
    "new_row = {'text':spam, 'spam':1}\n",
    "#append row to the dataframe\n",
    "data = data.append(new_row, ignore_index=True)\n",
    "print(data[\"text\"].iloc[-1])\n",
    "pred = model.predict(vect.transform(data[\"text\"]))\n",
    "print(\"---------------------------------\")\n",
    "print(\"Prediction: \",pred[-1])\n",
    "print(\"Actual category: \",data[\"spam\"].iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
